# Generated by copilot. Need to update, etc.
import pytest
import numpy as np
import healpy as hp
import os
import shutil
from astropy.table import Table
from cosmotheka.mappers.mapper_DESI_LRG import (
    MapperDESILRG,
    MapperDESILRGZhou2023,
)
import yaml

NSIDE = 32  # Healpix nside for the tests
NPIX = hp.nside2npix(NSIDE)


@pytest.fixture
def config(
    catalog_path,
    weights,
    dndz,
    stardens,
    imaging_weights_coeffs,
    lrg_mask_path,
    randoms,
):
    return {
        "zbin": 0,
        "data_catalog": catalog_path,
        "weights_catalog": weights,
        "file_dndz": dndz,
        "stardens_path": stardens,
        "imaging_weights_coeffs": imaging_weights_coeffs,
        "randoms_path": randoms,
        "randoms_selection": None,
        "randoms_lrgmask_path": lrg_mask_path,
        "nside": NSIDE,
        "coords": "C",
    }


@pytest.fixture
def rerun_config(config, tmp_path):
    config = config.copy()
    config["path_rerun"] = str(tmp_path)
    return config


@pytest.fixture
def config_with_islands(config):
    config = config.copy()
    config["remove_island"] = False
    return config


@pytest.fixture(scope="module")
def dndz(tmp_path_factory):
    cat = create_dndz()
    fn = tmp_path_factory.mktemp("data") / "dndz.fits"
    cat.write(fn, format="ascii", overwrite=True)
    return str(fn)


@pytest.fixture(scope="module")
def stardens(tmp_path_factory):
    # Create a dummy stardens Table
    half_on = np.append(np.ones(int(NPIX / 2)), np.zeros(int(NPIX / 2)))
    stardens = half_on * 3000  # Second half will have stardens below 2500

    stardens = Table({"HPXPIXEL": np.arange(NPIX), "STARDENS": stardens})
    fn = tmp_path_factory.mktemp("data") / "stardens.fits"
    stardens.write(fn, overwrite=True)
    return str(fn)


@pytest.fixture(scope="module")
def lrg_mask_path(tmp_path_factory):
    # Generate a catalog Table with columns
    half_on = np.append(np.ones(int(NPIX / 2)), np.zeros(int(NPIX / 2)))
    lrg_mask = half_on.copy()  # Half will pass the mask
    lrg_mask[:20] = 0  # Make first 20 pass too to test the other cuts
    cat = Table({"lrg_mask": lrg_mask})

    basedir = tmp_path_factory.mktemp("lrgmask_v1.1")
    fn10 = basedir / "randoms-1-0-lrgmask_v1.1.fits.gz"
    fn11 = basedir / "randoms-1-1-lrgmask_v1.1.fits.gz"
    cat.write(fn10, overwrite=True)
    cat.write(fn11, overwrite=True)
    return str(basedir)


@pytest.fixture(scope="module")
def catalog_path(tmp_path_factory):
    cat = get_catalog()
    fn = tmp_path_factory.mktemp("data") / "catalog.fits"
    cat.write(fn, overwrite=True)
    return str(fn)


@pytest.fixture
def catalog():
    return get_catalog()


@pytest.fixture(scope="module")
def weights(tmp_path_factory):
    cat = Table({"weight": np.ones(NPIX)})
    fn = tmp_path_factory.mktemp("data") / "weights.fits"
    cat.write(fn, overwrite=True)
    return str(fn)


@pytest.fixture(scope="module")
def randoms(tmp_path_factory):
    cat = get_catalog(randoms=True)
    basedir = tmp_path_factory.mktemp("randoms")
    fn10 = basedir / "randoms-1-0.fits"
    fn11 = basedir / "randoms-1-1.fits"
    cat.write(fn10, overwrite=True)
    cat.write(fn11, overwrite=True)
    return str(basedir)


def get_catalog(randoms=False, keep_lrgmask=False):
    hnpix = NPIX // 2

    # Generate a catalog Table with columns
    ra, dec = hp.pix2ang(NSIDE, np.arange(NPIX), lonlat=True)
    on = np.ones(NPIX)
    zeros = np.zeros(NPIX)
    three4th_on = np.append(
        np.ones(int(NPIX / 4)), np.zeros(3 * int(NPIX / 4))
    )

    # Make first half fail but due to different cuts
    nobs_g = on * 2  # This will pass the threshold
    nobs_g[:5] = 1  # Make first five fail
    nobs_r = on * 2  # This will pass the threshold
    nobs_r[5:10] = 1  # Make first five fail
    nobs_z = on * 2  # This will pass the threshold
    nobs_z[5:10] = 1  # Make first five fail
    maskbits = zeros.copy().astype(int)
    maskbits[10:20] = 2048  #  These will fail
    lrg_mask = three4th_on.copy()  # Last 3/4 will pass the mask
    lrg_mask[:20] = 0  # Make first 20 pass too to test the other cuts

    # Fluxes so that mag = 1
    flux = (5 / 10 ** (-2 / 5 + 9)) ** 2 * on

    # Half will pass the quality cuts and half the pzbin
    # Then, "remove_island" will remove more pixels
    cat = Table(
        {
            "RA": ra,
            "DEC": dec,
            # Starting pz_bin at 1, as the data. pz_bin == 1 are in the north
            "pz_bin": np.array([1, 2] * hnpix),
            # Columns used for the quality cuts
            "PIXEL_NOBS_G": nobs_g,
            "PIXEL_NOBS_R": nobs_r,
            "PIXEL_NOBS_Z": nobs_z,
            "MASKBITS": maskbits,
            "lrg_mask": lrg_mask,
            # Columns used for weights. With these values, the weights will be
            # w_North: 7, w_South: 14.
            "EBV": zeros,
            "GALDEPTH_G": flux,
            "GALDEPTH_R": flux,
            "GALDEPTH_Z": flux,
            "PSFSIZE_G": on,
            "PSFSIZE_R": on,
            "PSFSIZE_Z": on,
            "PHOTSYS": np.array(
                ["N", "S"] * hnpix
            ),  # Half will pass the masks
        }
    )

    if randoms:
        if not keep_lrgmask:
            # Useful for some tests
            cat.remove_column("lrg_mask")
        cat.remove_column("pz_bin")
        cat.rename_column("PIXEL_NOBS_G", "NOBS_G")
        cat.rename_column("PIXEL_NOBS_R", "NOBS_R")
        cat.rename_column("PIXEL_NOBS_Z", "NOBS_Z")

    return cat


@pytest.fixture(scope="module")
def imaging_weights_coeffs(tmp_path_factory):

    weights_dict = {}
    for bin_index in range(1, 5):
        n = 1 * bin_index
        for loc in ["north", "south"]:
            n += 0 if loc == "north" else 1  # Add 1 for south
            # For bin 1, the coefficients are: 1 and 2
            coeffs = {
                "EBV": n,
                "PSFSIZE_G": n,
                "PSFSIZE_R": n,
                "PSFSIZE_Z": n,
                "galdepth_gmag_ebv": n,
                "galdepth_rmag_ebv": n,
                "galdepth_zmag_ebv": n,
                "intercept": n,
            }
            weights_dict[f"{loc}_bin_{bin_index}"] = coeffs.copy()

    fn = tmp_path_factory.mktemp("data") / "imaging_weights_coeffs.yaml"
    with open(fn, "w") as f:
        yaml.dump(weights_dict, f)
    return str(fn)


def create_dndz():
    # Create a dummy dndz Table
    z_edges = np.linspace(0, 1.5, 100)
    z_mid = 0.5 * (z_edges[:-1] + z_edges[1:])
    nz = np.exp(
        -((z_mid - 0.5) ** 2) / (2 * 0.1**2)
    )  # Gaussian-like distribution
    dndz = Table(
        {
            "zmin": z_edges[:-1],
            "zmax": z_edges[1:],
            "z_mid": z_mid,
            "bin_1_combined": nz,
        }
    )
    return dndz


def get_mask_islands(cat):
    ra, dec = cat["RA"], cat["DEC"]

    toremove = (dec < -10.5) & (ra > 120) & (ra < 260)

    return toremove


@pytest.fixture()
def mapper(config):
    return MapperDESILRG(config)


@pytest.fixture()
def mapper_with_islands(config_with_islands):
    return MapperDESILRG(config_with_islands)


# Tests start here


def test_smoke(config):
    mapper = MapperDESILRG(config)
    mapper = MapperDESILRGZhou2023(config)


def test_rerun(rerun_config):
    m = MapperDESILRG(rerun_config)
    path_rerun = rerun_config["path_rerun"]

    # Noise
    nl = m.get_nl_coupled()
    fn = os.path.join(path_rerun, "DESI_LRG_Nell_coordC_ns32.npz")
    d = np.load(fn)
    assert d["nls"].size == 32 * 3
    assert np.all(nl == d["nls"])

    # Clean randoms
    clean_randoms = m.get_clean_randoms_with_weights("randoms-1-0")
    fn = os.path.join(path_rerun, "randoms-1-0_clean_weights.fits.gz")
    read_randoms = Table.read(fn)
    assert len(clean_randoms) == len(read_randoms)

    # Randoms maps
    random_maps = m.get_randoms_maps()
    fn = os.path.join(
        path_rerun, "map_DESI_LRG_randoms-1-0_n-w-w2_coordC_ns32.fits.gz"
    )
    read_maps = hp.read_map(fn, verbose=False, field=None)

    fn = os.path.join(
        path_rerun, "map_DESI_LRG_randoms-1-1_n-w-w2_coordC_ns32.fits.gz"
    )
    read_maps += hp.read_map(fn, verbose=False, field=None)

    assert np.all(read_maps[0] == random_maps["n"])
    assert np.all(read_maps[1] == random_maps["w"])
    assert np.all(read_maps[2] == random_maps["w2"])


def test_get_default_cuts(mapper):
    cuts = m._get_default_cuts()
    assert isinstance(cuts, dict)
    assert cuts == {
        "min_nobs": 2,
        "target_maskbits": [1, 12, 13],
        "max_ebv": 0.15,
        "max_stardens": 2500,
        "remove_island": True,
    }


@pytest.mark.parametrize(
    ("key", "val"),
    [
        ("target_maskbits", [1, 12, 14]),
        ("min_nobs", 3),
        ("max_ebv", 0.2),
        ("max_stardens", 3000),
        ("remove_island", False),
    ],
)
def test_suffix_generation(config, key, val):
    config[key] = val  # change from default
    mapper = MapperDESILRG(config)
    assert key.replace("_", "") in mapper.suffix


def test_suffix_generation_all_keys(config):
    # Set all keys to non-default values
    config["target_maskbits"] = [1, 12, 14]
    config["min_nobs"] = 3
    config["max_ebv"] = 0.2
    config["max_stardens"] = 3000
    config["remove_island"] = False

    mapper = MapperDESILRG(config)
    suffix = mapper.suffix

    # Check that all keys are reflected in the suffix
    s = []
    for key in sorted(
        [
            "target_maskbits",
            "min_nobs",
            "max_ebv",
            "max_stardens",
            "remove_island",
        ]
    ):
        s.append(key.replace("_", "") + str(config[key]))

    assert suffix == "_".join(s)


def test__get_stardens_mask(mapper, catalog):
    # Also tested through quality cuts and get_catalog and randoms
    mask = mapper._get_stardens_mask(catalog)
    assert np.sum(mask) == NPIX / 2
    assert np.all(mask[NPIX // 2 :])
    assert not np.any(mask[: NPIX // 2])


@pytest.mark.parametrize("randoms", [False, True])
def test__get_quality_cuts(config, randoms):
    # TODO: To test this properly, we might need to change a bit the catalog or
    # stardens
    catalog = get_catalog(randoms=randoms, keep_lrgmask=True)

    config2 = config.copy()
    config2["remove_island"] = False
    mapper = MapperDESILRG(config2)

    mask = mapper._get_quality_cuts(catalog, randoms)
    assert np.sum(mask) == NPIX / 2
    assert np.all(mask[NPIX // 2 :])
    assert not np.any(mask[: NPIX // 2])

    mapper = MapperDESILRG(config)
    mask_islands = get_mask_islands(catalog)
    mask_noisland = mapper._get_quality_cuts(catalog, randoms)

    assert np.all(mask * (~mask_islands) == mask_noisland)


def test_get_catalog(config):
    config2 = config.copy()
    # Don't remove islands for this test to make count easier
    config2["remove_island"] = False  # Default is True
    mapper = MapperDESILRG(config2)
    cat = mapper.get_catalog()
    assert len(mapper.cat) == NPIX / 4

    mask = get_mask_islands(cat)
    cat = cat[~mask]  # Remove islands

    mapper = MapperDESILRG(config)
    mapper.get_catalog()
    assert len(mapper.cat) == len(cat)


def test_get_nz(mapper, dndz):
    dndz = create_dndz()
    nz = mapper.get_nz()
    print(dndz["z_mid"])
    assert np.all(dndz["z_mid"] == nz[0])
    assert np.all(dndz["bin_1_combined"] == nz[1])


@pytest.mark.parametrize("mapper", [MapperDESILRG, MapperDESILRGZhou2023])
def test__get_alpha(config_with_islands, mapper):
    # We keep the islands so that the number of north and south elements are the
    # same
    m = mapper(config_with_islands)
    alpha_mapper = m._get_alpha()
    # Remember w_North = 7, w_South = 14 and that we have 2 randoms files so
    # w_North = 14, w_South = 28 per pixel (we have 1 galaxy per pixel)
    # In addition, recall that we are only using 1/4th of the catalog for the
    # "data" after pz_bin == 1. Recall that pz_bin == 1 choses galaxies only in
    # the north.
    if isinstance(m, MapperDESILRGZhou2023):
        # <data / randoms> = 1/2 / w_north
        alpha = 1 / 28
    else:
        # <data> / <randoms> = [1/2 / (1/2 * w_North + 1/2 * w_South)]
        # = 1 / (w_North + w_South)
        alpha = 1 / 42

    assert alpha_mapper == pytest.approx(alpha, rel=1e-5)


def test_get_data_maps(mapper_with_islands):
    maps = mapper_with_islands.get_data_maps()
    assert maps["n"] is maps["w"]
    assert maps["n"] is maps["w2"]
    assert np.all(maps["n"][maps["n"] != 0] == 1)
    assert np.sum(maps["n"]) == NPIX / 4


@pytest.mark.parametrize("mapper", [MapperDESILRG, MapperDESILRGZhou2023])
def test__get_signal_map(config_with_islands, mapper):
    m = mapper(config_with_islands)
    signal_map = m._get_signal_map()
    assert signal_map.size == NPIX
    assert np.mean(signal_map) == pytest.approx(0, rel=1e-5)

    vals = np.unique(signal_map)
    if isinstance(m, MapperDESILRGZhou2023):
        mask_vals = 1  # = 1 / 28 * 28
        data_vals = 1
        assert vals == pytest.approx([-1, 0, mask_vals], rel=1e-5)
    else:
        vals = np.unique(signal_map)
        mask_vals_north = 1 / 42 * 14
        mask_vals_south = 1 / 42 * 28
        data_vals_north = 1
        data_vals_south = 0  # South patch from data by zbin==1
        assert vals == pytest.approx(
            [
                data_vals_south - mask_vals_south,
                0,
                data_vals_north - mask_vals_north,
            ],
            rel=1e-5,
        )


@pytest.mark.parametrize("mapper", [MapperDESILRG, MapperDESILRGZhou2023])
def test__get_mask(config_with_islands, mapper):
    m = mapper(config_with_islands)
    mask = m._get_mask()
    values = np.unique(mask)
    if isinstance(m, MapperDESILRGZhou2023):
        assert np.all(values == [0, 1])
        assert np.sum(mask) == NPIX / 2
        assert np.sum(mask[: NPIX // 2]) == 0
        # Half of the randoms pass the cuts, since zbin selection does not apply
        assert np.sum(mask[NPIX // 2 :]) == NPIX / 2
    else:
        mask_vals_north = 1 / 42 * 14
        mask_vals_south = 1 / 42 * 28
        assert values == pytest.approx(
            [0, mask_vals_north, mask_vals_south], rel=1e-5
        )
        assert np.sum(mask[: NPIX // 2]) == 0
        assert np.sum(mask[NPIX // 2 :]) == pytest.approx(
            NPIX / 4 * (mask_vals_north + mask_vals_south), rel=1e-5
        )
        assert mask[NPIX // 2 :: 2] == pytest.approx(mask_vals_north, rel=1e-5)
        assert mask[NPIX // 2 + 1 :: 2] == pytest.approx(
            mask_vals_south, rel=1e-5
        )


@pytest.mark.parametrize("mapper", [MapperDESILRG, MapperDESILRGZhou2023])
def test__get_nl_coupled(config_with_islands, mapper):
    m = mapper(config_with_islands)
    nl = m._get_nl_coupled()["nls"]
    assert nl.size == NSIDE * 3

    area = hp.nside2pixarea(NSIDE, degrees=False)
    # Recall that by construction
    # w_data = w2_data = 1,
    # w_North = 7, w_South = 14,
    # We have 2 randoms so w = 14 (North), 28 (South)
    if isinstance(m, MapperDESILRGZhou2023):
        # shot = Npix^good * A_pix * fsky *\sum_p (<w2>) / (\sum <w>)**2
        # with <*> = \sum_p w_p^data / N_rands
        # N_rands = 2 since we have 2 randoms, so
        # <*> is w = 7 (North), 14 (South)
        # Data is only in the north, so the last line becomes
        # 1 / Npix^data * (1/49) / (1/7)**2 = 4/Npix * 1
        expected_nl = NPIX / 2 * area * 0.5 / (NPIX / 4)
    else:
        # w2_p^randoms = 2*7^2 = 98 (North), 2*14^2 = 392 (South)
        # Nell = area_pix^2 / 4pi * sum_p w2_p^data + alpha^2 w2_p^randoms
        # alpha = 1 / 42
        expected_nl = (
            area**2
            / (4 * np.pi)
            * (NPIX / 4 + (1 / 42) ** 2 * NPIX / 4 * (98 + 392))
        )
    assert nl == pytest.approx(expected_nl, rel=1e-5)


def test_get_nl_coupled(mapper):
    nl = mapper.get_nl_coupled()
    assert np.all(nl == mapper._get_nl_coupled()["nls"])


# TODO:
def test___get_clean_randoms_with_weights():
    pass


# TODO:
def test_get_clean_randoms_with_weights():
    pass


# TODO:
def test_get_randoms_maps():
    pass


# TODO:
def test__get_list_randoms():
    pass


# TODO:
def test_compute_weights():
    pass


# TODO:
def test__load_full_randoms():
    pass


# TODO:
def test__compute_weights_for_zbin():
    pass
