# Generated by copilot. Need to update, etc.
import pytest
import numpy as np
import healpy as hp
import os
import shutil
from astropy.table import Table
from cosmotheka.mappers.mapper_DESI_LRG import (
    MapperDESILRG,
    MapperDESILRGZhou2023,
)
import yaml


@pytest.fixture
def config(
    catalog,
    weights,
    dndz,
    stardens,
    imaging_weights_coeffs,
    lrg_mask_path,
    randoms,
):
    return {
        "zbin": 0,
        "data_catalog": catalog,
        "weights_catalog": weights,
        "file_dndz": dndz,
        "stardens_path": stardens,
        "imaging_weights_coeffs": imaging_weights_coeffs,
        "randoms_path": randoms,
        "randoms_selection": None,
        "randoms_lrgmask_path": lrg_mask_path,
        "nside": 32,
        "coords": "C",
    }


@pytest.fixture
def rerun_config(config, tmp_path):
    config = config.copy()
    config["path_rerun"] = str(tmp_path)
    return config


@pytest.fixture(scope="module")
def dndz(tmp_path_factory):
    cat = create_dndz()
    fn = tmp_path_factory.mktemp("data") / "dndz.fits"
    cat.write(fn, overwrite=True)
    return str(fn)


@pytest.fixture(scope="module")
def stardens(tmp_path_factory):
    # Create a dummy stardens Table
    npix = hp.nside2npix(32)
    half_on = np.append(np.ones(int(npix / 2)), np.zeros(int(npix / 2)))
    stardens = half_on * 3000  # Second half will have stardens below 2500

    stardens = Table({"HPXPIXEL": np.arange(npix), "STARDENS": stardens})
    fn = tmp_path_factory.mktemp("data") / "stardens.fits"
    stardens.write(fn, overwrite=True)
    return str(fn)


@pytest.fixture(scope="module")
def lrg_mask_path(tmp_path_factory):
    nside = 32
    npix = hp.nside2npix(nside)
    # Generate a catalog Table with columns
    half_on = np.append(np.ones(int(npix / 2)), np.zeros(int(npix / 2)))
    lrg_mask = half_on.copy()  # Half will pass the mask
    lrg_mask[:20] = 0  # Make first 20 pass too to test the other cuts
    cat = Table({"lrg_mask": lrg_mask})

    basedir = tmp_path_factory.mktemp("lrgmask_v1.1")
    fn10 = basedir / "randoms-1-0-lrgmask_v1.1.fits.gz"
    fn11 = basedir / "randoms-1-1-lrgmask_v1.1.fits.gz"
    cat.write(fn10, overwrite=True)
    cat.write(fn11, overwrite=True)
    return str(basedir)


@pytest.fixture(scope="module")
def catalog(tmp_path_factory):
    cat = get_catalog()
    fn = tmp_path_factory.mktemp("data") / "catalog.fits"
    cat.write(fn, overwrite=True)
    return str(fn)


@pytest.fixture(scope="module")
def weights(tmp_path_factory):
    cat = Table({"weight": np.ones(hp.nside2npix(32))})
    fn = tmp_path_factory.mktemp("data") / "weights.fits"
    cat.write(fn, overwrite=True)
    return str(fn)


@pytest.fixture(scope="module")
def randoms(tmp_path_factory):
    cat = get_catalog(randoms=True)
    basedir = tmp_path_factory.mktemp("randoms")
    fn10 = basedir / "randoms-1-0.fits"
    fn11 = basedir / "randoms-1-1.fits"
    cat.write(fn10, overwrite=True)
    cat.write(fn11, overwrite=True)
    return str(basedir)


def get_catalog(randoms=False):
    nside = 32
    npix = hp.nside2npix(nside)
    hnpix = npix // 2

    # Generate a catalog Table with columns
    ra, dec = hp.pix2ang(nside, np.arange(npix), lonlat=True)
    on = np.ones(npix)
    zeros = np.zeros(npix)
    three4th_on = np.append(
        np.ones(int(npix / 4)), np.zeros(3 * int(npix / 4))
    )

    # Make first half fail but due to different cuts
    nobs_g = on * 2  # This will pass the threshold
    nobs_g[:5] = 1  # Make first five fail
    nobs_r = on * 2  # This will pass the threshold
    nobs_r[5:10] = 1  # Make first five fail
    nobs_z = on * 2  # This will pass the threshold
    nobs_z[5:10] = 1  # Make first five fail
    maskbits = zeros.copy().astype(int)
    maskbits[10:20] = 2048  #  These will fail
    lrg_mask = three4th_on.copy()  # Last 3/4 will pass the mask
    lrg_mask[:20] = 0  # Make first 20 pass too to test the other cuts

    # Fluxes so that mag = 1
    flux = (5 / 10 ** (-2 / 5 + 9)) ** 2 * on

    # Half will pass the quality cuts and half the pzbin
    # Then, "remove_island" will remove more pixels
    cat = Table(
        {
            "RA": ra,
            "DEC": dec,
            "pz_bin": np.array([1, 2] * hnpix),  # Starting on 1, as the data
            # Columns used for the quality cuts
            "PIXEL_NOBS_G": nobs_g,
            "PIXEL_NOBS_R": nobs_r,
            "PIXEL_NOBS_Z": nobs_z,
            "MASKBITS": maskbits,
            "lrg_mask": lrg_mask,
            # Columns used for weights. With these values, the weights will be
            # w_North: 7, w_South: 14.
            "EBV": zeros,
            "GALDEPTH_G": flux,
            "GALDEPTH_R": flux,
            "GALDEPTH_Z": flux,
            "PSFSIZE_G": on,
            "PSFSIZE_R": on,
            "PSFSIZE_Z": on,
            "PHOTSYS": np.array(
                ["N", "S"] * hnpix
            ),  # Half will pass the masks
        }
    )

    if randoms:
        cat.remove_column("lrg_mask")
        cat.remove_column("pz_bin")
        cat.rename_column("PIXEL_NOBS_G", "NOBS_G")
        cat.rename_column("PIXEL_NOBS_R", "NOBS_R")
        cat.rename_column("PIXEL_NOBS_Z", "NOBS_Z")

    return cat


@pytest.fixture(scope="module")
def imaging_weights_coeffs(tmp_path_factory):

    weights_dict = {}
    for bin_index in range(1, 5):
        n = 1 * bin_index
        for loc in ["north", "south"]:
            n += 0 if loc == "north" else 1  # Add 1 for south
            # For bin 1, the coefficients are: 1 and 2
            coeffs = {
                "EBV": n,
                "PSFSIZE_G": n,
                "PSFSIZE_R": n,
                "PSFSIZE_Z": n,
                "galdepth_gmag_ebv": n,
                "galdepth_rmag_ebv": n,
                "galdepth_zmag_ebv": n,
                "intercept": n,
            }
            weights_dict[f"{loc}_bin_{bin_index}"] = coeffs.copy()

    fn = tmp_path_factory.mktemp("data") / "imaging_weights_coeffs.yaml"
    with open(fn, "w") as f:
        yaml.dump(weights_dict, f)
    return str(fn)


def create_dndz():
    # Create a dummy dndz Table
    z_edges = np.linspace(0, 1.5, 100)
    z_mid = 0.5 * (z_edges[:-1] + z_edges[1:])
    nz = np.exp(
        -((z_mid - 0.5) ** 2) / (2 * 0.1**2)
    )  # Gaussian-like distribution
    dndz = Table(
        {"zmin": z_edges[:-1], "zmax": z_edges[1:], "z_mid": z_mid, "nz": nz}
    )
    return dndz


def get_mask_islands(cat):
    ra, dec = cat["RA"], cat["DEC"]

    toremove = (dec < -10.5) & (ra > 120) & (ra < 260)

    return toremove


@pytest.fixture()
def mapper(config):
    return MapperDESILRG(config)


# Tests start here


def test_smoke(config):
    config2 = config.copy()
    # Don't remove islands for this test to make count easier
    config2["remove_island"] = False  # Default is True
    mapper = MapperDESILRG(config2)
    cat = mapper.get_catalog()
    assert len(mapper.cat) == hp.nside2npix(32) / 4

    mask = get_mask_islands(cat)
    cat = cat[~mask]  # Remove islands

    mapper = MapperDESILRG(config)
    mapper.get_catalog()
    assert len(mapper.cat) == len(cat)


def test_rerun(rerun_config):
    m = MapperDESILRG(rerun_config)
    path_rerun = rerun_config["path_rerun"]

    # Noise
    nl = m.get_nl_coupled()
    fn = os.path.join(path_rerun, "DESI_LRG_Nell_coordC_ns32.npz")
    d = np.load(fn)
    assert d["nls"].size == 32 * 3
    assert np.all(nl == d["nls"])

    # Clean randoms
    clean_randoms = m.get_clean_randoms_with_weights("randoms-1-0")
    fn = os.path.join(path_rerun, "randoms-1-0_clean_weights.fits.gz")
    read_randoms = Table.read(fn)
    assert len(clean_randoms) == len(read_randoms)

    # Randoms maps
    random_maps = m.get_randoms_maps()
    fn = os.path.join(
        path_rerun, "map_DESI_LRG_randoms-1-0_n-w-w2_coordC_ns32.fits.gz"
    )
    read_maps = hp.read_map(fn, verbose=False, field=None)

    fn = os.path.join(
        path_rerun, "map_DESI_LRG_randoms-1-1_n-w-w2_coordC_ns32.fits.gz"
    )
    read_maps += hp.read_map(fn, verbose=False, field=None)

    assert np.all(read_maps[0] == random_maps["n"])
    assert np.all(read_maps[1] == random_maps["w"])
    assert np.all(read_maps[2] == random_maps["w2"])


def test_get_default_cuts(mapper):
    cuts = m._get_default_cuts()
    assert isinstance(cuts, dict)
    assert cuts == {
        "min_nobs": 2,
        "target_maskbits": [1, 12, 13],
        "max_ebv": 0.15,
        "max_stardens": 2500,
        "remove_island": True,
    }


@pytest.mark.parametrize(
    ("key", "val"),
    [
        ("target_maskbits", [1, 12, 14]),
        ("min_nobs", 3),
        ("max_ebv", 0.2),
        ("max_stardens", 3000),
        ("remove_island", False),
    ],
)
def test_suffix_generation(config, key, val):
    config[key] = val  # change from default
    mapper = MapperDESILRG(config)
    assert key.replace("_", "") in mapper.suffix


def test_suffix_generation_all_keys(config):
    # Set all keys to non-default values
    config["target_maskbits"] = [1, 12, 14]
    config["min_nobs"] = 3
    config["max_ebv"] = 0.2
    config["max_stardens"] = 3000
    config["remove_island"] = False

    mapper = MapperDESILRG(config)
    suffix = mapper.suffix

    # Check that all keys are reflected in the suffix
    s = []
    for key in sorted(
        [
            "target_maskbits",
            "min_nobs",
            "max_ebv",
            "max_stardens",
            "remove_island",
        ]
    ):
        s.append(key.replace("_", "") + str(config[key]))

    assert suffix == "_".join(s)


# TODO:
def test_get_stardens_mask(monkeypatch):
    config = get_config()
    mapper = MapperDESILRG(config)
    # Patch fitsio.read and hp.npix2nside
    monkeypatch.setattr(
        "fitsio.read",
        lambda fname: Table({"HPXPIXEL": [0, 1], "STARDENS": [1000, 3000]}),
    )
    monkeypatch.setattr("healpy.npix2nside", lambda n: 2)
    monkeypatch.setattr(
        "healpy.ang2pix", lambda nside, ra, dec, lonlat: np.array([0, 1])
    )
    cat = Table({"RA": [0, 1], "DEC": [0, 1]})
    mask = mapper._get_stardens_mask(cat)
    assert isinstance(mask, np.ndarray)


# TODO:
def test_get_quality_cuts(monkeypatch):
    config = get_config()
    mapper = MapperDESILRG(config)
    # Patch _get_stardens_mask
    monkeypatch.setattr(
        mapper, "_get_stardens_mask", lambda cat: np.array([True, False, True])
    )
    cat = Table(
        {
            "lrg_mask": [0, 1, 0],
            "MASKBITS": [0, 0, 0],
            "PIXEL_NOBS_G": [2, 2, 2],
            "PIXEL_NOBS_R": [2, 2, 2],
            "PIXEL_NOBS_Z": [2, 2, 2],
            "EBV": [0.1, 0.2, 0.05],
            "RA": [0, 1, 2],
            "DEC": [0, 1, 2],
        }
    )
    mask = mapper._get_quality_cuts(cat)
    assert isinstance(mask, np.ndarray)


# TODO:
def test_get_catalog():
    pass


# TODO:
def test_get_nz():
    pass


# TODO:
@pytest.mark.parametrize("mapper", [MapperDESILRG, MapperDESILRGZhou2023])
def test__get_alpha(mapper):
    pass


# TODO:
def test_get_data_maps():
    pass


# TODO:
@pytest.mark.parametrize("mapper", [MapperDESILRG, MapperDESILRGZhou2023])
def test__get_signal_map(mapper):
    pass


# TODO:
@pytest.mark.parametrize("mapper", [MapperDESILRG, MapperDESILRGZhou2023])
def test__get_mask(mapper):
    pass


# TODO:
@pytest.mark.parametrize("mapper", [MapperDESILRG, MapperDESILRGZhou2023])
def test__get_nl_coupled(mapper):
    pass


# TODO:
def test_get_nl_coupled():
    pass


# TODO:
def test___get_clean_randoms_with_weights():
    pass


# TODO:
def test_get_clean_randoms_with_weights():
    pass


# TODO:
def test_get_randoms_maps():
    pass


# TODO:
def test__get_list_randoms():
    pass


# TODO:
def test_compute_weights():
    pass


# TODO:
def test__load_full_randoms():
    pass


# TODO:
def test__compute_weights_for_zbin():
    pass


def test_compute_weights(monkeypatch):
    config = get_config()
    mapper = MapperDESILRG(config)
    # Patch yaml.safe_load
    monkeypatch.setattr(
        "yaml.safe_load",
        lambda f: {
            "north_bin_1": {"intercept": 1, "A": 0},
            "south_bin_1": {"intercept": 1, "A": 0},
            "north_bin_2": {"intercept": 1, "A": 0},
            "south_bin_2": {"intercept": 1, "A": 0},
            "north_bin_3": {"intercept": 1, "A": 0},
            "south_bin_3": {"intercept": 1, "A": 0},
            "north_bin_4": {"intercept": 1, "A": 0},
            "south_bin_4": {"intercept": 1, "A": 0},
        },
    )
    # Patch open
    monkeypatch.setattr("builtins.open", lambda f, mode=None: f)
    # Patch _compute_weights_for_zbin
    monkeypatch.setattr(
        mapper,
        "_compute_weights_for_zbin",
        lambda randoms, coeffs, bin_index: np.ones(len(randoms)),
    )
    randoms = Table(
        {
            "GALDEPTH_G": [1.0],
            "GALDEPTH_R": [1.0],
            "GALDEPTH_Z": [1.0],
            "EBV": [0.1],
            "PHOTSYS": ["N"],
            "A": [1.0],
        }
    )
    weights = mapper.compute_weights(randoms)
    assert isinstance(weights, dict)
    assert any(
        "weight_pzbin" in k or "weight_noebv_pzbin" in k for k in weights
    )


def test_zhou2023_get_alpha_and_mask(monkeypatch):
    config = get_config()
    mapper = MapperDESILRGZhou2023(config)
    # Patch get_randoms_maps and get_data_maps
    monkeypatch.setattr(
        mapper,
        "get_randoms_maps",
        lambda: {"w": np.array([2.0, 4.0, 0.0, 10.0])},
    )
    monkeypatch.setattr(
        mapper, "get_data_maps", lambda: {"n": np.array([4.0, 8.0, 0.0, 20.0])}
    )
    # Patch _get_alpha to set alpha
    mapper.alpha = 2.0
    # Test _get_mask
    mask = mapper._get_mask()
    assert np.all((mask == 1.0) | (mask == 0.0))
    # Test _get_signal_map
    signal_map = mapper._get_signal_map()
    assert isinstance(signal_map, np.ndarray)
    # Test _get_alpha returns alpha
    assert mapper._get_alpha() == 2.0
